{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4\n",
    "---\n",
    "Here we're just importing all the libraries we'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import random as rnd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Hashing Task!\n",
    "---\n",
    "### Bloom Filter class\n",
    "In this first section of the task we are going to write a Bloom Filter class, i.e. a class representing and implementing everything a bloom filter should be and should do. This will be useful for a more structured as well as a more organized code.\n",
    "\n",
    "This bloom filter class will have two instance attributes: <code>Bloom_Filter.array</code> and <code>Bloom_Filter.hash_functions</code>. The first will contain the array representing the bloom filter, the second is a list of hash functions which will be used to insert and search elements on the data structure. \n",
    "\n",
    "To represent <code>Bloom_Filter.array</code> we're going to use a numpy array instead of a simple Python list. That's because we'll work with very large arrays and numpy is a lot more efficient both in terms of memory and in terms of computational efficiency.\n",
    "\n",
    "The initializer of the class will take two parameters: the size <code>size</code> of the array representing the bloom filter and the list of hash functions <code>hash_function</code> which will be used to work with the data structure. Both these properties are private and immutable so it will not be possible to change the behaviour of a bloom filter once it is initialized with our class.\n",
    "\n",
    "In the end the class will have two instance methods: <code>Bloom_Filter.insert(element)</code> and <code>Bloom_Filter.check(element)</code> for inserting and searching items on the bloom filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class is going to represent a bloom filter, so that we can organize all the implementation and methods\n",
    "# of the data structure in a single class.\n",
    "class Bloom_Filter:\n",
    "    \n",
    "    # To the constructor we're going to pass the size of the array representing the bloom filter\n",
    "    # and the list of hash functions that will be used for our methods\n",
    "    def __init__(self, size, hash_functions):\n",
    "        self._array = np.empty(size, dtype = bool)\n",
    "        self._hash_functions = hash_functions\n",
    "    \n",
    "    # This function is for adding elements to the bloom filter\n",
    "    def insert(self, element):\n",
    "        for function in self._hash_functions:\n",
    "            self._array[function(element)] = True\n",
    "            \n",
    "    # This function is for checking if an element is possibly on the bloom filter or definitely not in it.\n",
    "    # It returns True if the element is possibly on it, False if it's definetely not on it.\n",
    "    def check(self, element):\n",
    "        for function in self._hash_functions:\n",
    "            if(not self._array[function(element)]):\n",
    "                return(False)\n",
    "        return(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing parameters\n",
    "Since we are going to use a bloom filter for our task, one of the first things we have to do is choosing the size $m$ of the array representing it. We know the folllowing approximate formula to get a reasonable value of $m$ given an error tolerance $p$ as well as the size $n$ of the elements we are going to insert on the set:\n",
    "$$\n",
    "    m = -\\frac{n \\ln{p}}{(\\ln{2})^{2}}\n",
    "$$.\n",
    "\n",
    "For the error tolerance $p$ we are going to choose the value $0.01$ so that we'll have only a $1\\%$ rate of false positives.\n",
    "\n",
    "To find $n$ we are going to inspect the data we are given. Obviously, since the purpose of the task is to not save all the given passwords in memory, we are going to count the number of passwords **without** saving all of them in memory. To do this we are just going to open our file of passwords and count how many lines it has (since we already know there's a password per line) by using a counter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000000\n"
     ]
    }
   ],
   "source": [
    "passwords = open(\"passwords1.txt\", \"r\")\n",
    "# It's worth noting that when Python opens a file it's not going to save it in memory\n",
    "# so we are not cheating on our task by just opening the file if we don't read it all at once\n",
    "\n",
    "counter = 0\n",
    "while(passwords.readline()):\n",
    "    counter = counter + 1\n",
    "passwords.close()\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have found out thar our list consists of $100$ milions passwords. Knowing this we can finally compute $m$ with the formula given above and get\n",
    "$$\n",
    "    m = 958505838\n",
    "$$.\n",
    "\n",
    "Having established $p$ and $m$ we only need to find the number of hash functions $k$ we're going to code and use for our task. Again, there's a formula with which we'll get $k$ easily:\n",
    "$$\n",
    "    k = \\frac{m}{n}\\ln{2}\n",
    "$$ and we get\n",
    "$$\n",
    "    k = 6.64\n",
    "$$ so we're going to use seven hash functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hash functions\n",
    "This is one critical section. Here we are going to code the hash functions we'll use for our bloom filter. As we have established on the previous sections we are going to code seven of these functions and we'll try to make them as good as we can, meaning that not only they need to be good hash functions, but also independent from each other so to increase the efficiency of our data structure.\n",
    "\n",
    "A good hash function really depends on the distribution of the elements it's going to convert. That's why, before coding our functions, we're going to insepect our passwords data hoping to find some information about its underlying distribution.\n",
    "\n",
    "We already know that a password is a string of 20 characters, so we want to find what characters are possibly contained in a password as well as if some characters tend to appear more often than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 !\n",
      "122 z\n"
     ]
    }
   ],
   "source": [
    "passwords = open(\"passwords1.txt\", \"r\")\n",
    "\n",
    "# We're going to save the minimum as well the maximum possible character in our file (characters are ordered by their ASCII code)\n",
    "minimum = 102\n",
    "maximum = 102\n",
    "\n",
    "# We're going to look at only the first 1'000'000 entries of the file so to speed up the process\n",
    "# implicitly assuming that the underlying distribution is homogenous throughout the file\n",
    "for _ in range(1000000):\n",
    "    string = passwords.readline()\n",
    "    for character in string[:19]: # It's important we get rid of the last character, which is always a \"\\n\"\n",
    "        if(ord(character) < minimum):\n",
    "            minimum = ord(character)\n",
    "        if(ord(character) > maximum):\n",
    "            maximum = ord(character)\n",
    "\n",
    "print(minimum, chr(minimum))\n",
    "print(maximum, chr(maximum))\n",
    "passwords.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that every password can contain characters ranging from \"!\" to \"z\".\n",
    "\n",
    "We now want to know if any of this character appears more often than the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "passwords = open(\"passwords1.txt\", \"r\")\n",
    "\n",
    "# Here we're going to save how many times a character appears on the file, at position i will be the number of times\n",
    "# chr(i + 33) appeared\n",
    "counter = [0] * (122 - 33 + 1)\n",
    "\n",
    "# Again we're just looking at the first 1'000'000 to speed up the process\n",
    "for _ in range(1000000):\n",
    "    string = passwords.readline()\n",
    "    for character in string[:19]:\n",
    "        counter[ord(character) - 33] += 1\n",
    "\n",
    "passwords.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[226536,\n",
       " 226375,\n",
       " 226357,\n",
       " 226105,\n",
       " 226044,\n",
       " 226000,\n",
       " 226268,\n",
       " 226404,\n",
       " 225767,\n",
       " 225890,\n",
       " 225885,\n",
       " 226388,\n",
       " 226831,\n",
       " 225541,\n",
       " 225986,\n",
       " 226636,\n",
       " 225616,\n",
       " 227077,\n",
       " 226304,\n",
       " 227385,\n",
       " 226377,\n",
       " 225768,\n",
       " 226336,\n",
       " 226474,\n",
       " 226330,\n",
       " 226024,\n",
       " 226416,\n",
       " 226617,\n",
       " 226811,\n",
       " 226216,\n",
       " 226053,\n",
       " 226097,\n",
       " 225798,\n",
       " 226659,\n",
       " 225852,\n",
       " 226279,\n",
       " 226296,\n",
       " 226135,\n",
       " 226755,\n",
       " 226109,\n",
       " 226002,\n",
       " 225869,\n",
       " 226628,\n",
       " 225940,\n",
       " 226091,\n",
       " 226075,\n",
       " 225593,\n",
       " 225928,\n",
       " 225867,\n",
       " 226701,\n",
       " 225958,\n",
       " 226349,\n",
       " 226193,\n",
       " 226762,\n",
       " 225935,\n",
       " 226347,\n",
       " 226287,\n",
       " 226075,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 226032,\n",
       " 225611,\n",
       " 226913,\n",
       " 226309,\n",
       " 225951,\n",
       " 226027,\n",
       " 225492,\n",
       " 226486,\n",
       " 225835,\n",
       " 225963,\n",
       " 226979,\n",
       " 226746,\n",
       " 225956,\n",
       " 226440,\n",
       " 226128,\n",
       " 225894,\n",
       " 225349,\n",
       " 225799,\n",
       " 226374,\n",
       " 226345,\n",
       " 225788,\n",
       " 225929,\n",
       " 225759,\n",
       " 225880,\n",
       " 226971,\n",
       " 225647]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at this list we get two useful informations. First of all we see that characters whose ASCII code ranges from 91 ton 96 never appear on the file. Moreover we note that the remaining character appear, approximately, with the same probability in a password.\n",
    "\n",
    "Based on all these informations we're going to make the following assumption: every password in the file is a randome string where every character is independently drawn in the set of characters whose ASCII code ranges from 33 to 122, excluding those one whose code ranges from 91 to 96.\n",
    "\n",
    "The efficiency of the algorithms we're going to use will tell us if this has been a reasonable assumption, but for now we stick to it.\n",
    "\n",
    "#### First hash function\n",
    "\n",
    "For our first hash function we're going to read every password as a number in base $84$ (the numbers of possible characters appearing in a password) and then take the remainder of the division between this number and $958505838$. This should be a good hash function for the following reason: based on our previous assumption, a password is a number drawn uniformly from $0$ to $84^{20} - 1$. Given a number $x$ such that $0 \\leq x < 958505838$ we get that the probability $p(x)$ of getting $x$ from a random password with this function is approximately $\\frac{1}{958505838}$.\n",
    "\n",
    "For now we code a function to get the base 10 value of a character which will be needed to treat every string as a number in base 84."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_10(character):\n",
    "    value = ord(character)\n",
    "    \n",
    "    # We remember that values ranging from 91 to 96 do not appear\n",
    "    if(value < 91):\n",
    "        return(value - 33)\n",
    "    else:\n",
    "        return(value - 39)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to code our first hash function <code>hash_1(string)</code>. Given a string $x_1x_2x_3\\cdots x_{20}$ this will represent the number\n",
    "$$\n",
    "    x_{1} + x_{2} 84 + x_{3} 84^{2} + \\cdots + x_{20} 84^{19}\n",
    "$$ and what we need is to take the ramainder between this number and $958505838$. To do this we're going to use Horner's method to compute a polynomial, always working $\\text{mod } 958505838$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_1(string):\n",
    "    value  = 0\n",
    "    for index in range(len(string) - 1, -1, -1):\n",
    "        value = (84 * value + get_base_10(string[index])) % 958505838\n",
    "    return(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other hash functions\n",
    "\n",
    "For the other six hash functions we're going to change a little our first function <code>hash_1</code>. In fact we're going to use exactly this function, but instead of using it in our normal string, we're reordering the characters of the string and apply the function to the result.\n",
    "\n",
    "To start we're going to define a function to change, in some way, the order of characters in a string. We can't change this order casually, since every hash function must be deterministic. What we do is rotating the characters in a string by a step $s$ and this should be enough to obtain a totally different value from the one resulting from <code>hash_1</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_string(string, step):\n",
    "    return(string[step:] + string[:step])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now define our other six functions and since they will be all similar we're going to define an high order function which will take as parameters one hash function (in our case <code>hash_1</code>) and a number $k$ and will return our $k$-th hash function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_function(first_hash_function, k):\n",
    "    \n",
    "    # Our k-th hash function will just apply hash_1 to the string rotated by k steps\n",
    "    return(lambda x : hash_1(rotate_string(x, k - 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now save all our hash functions in a list so that we can pass it as a parameter when we're going to inizialize our <code>Bloom_Filter</code> class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_functions = [hash_function(hash_1, index + 1) for index in range(7)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have already said at the start of the sections, even if our functions seem to be good hash functions by themselves, it's not guaranteed that they are good hash functions for our bloom filter implementation. It could happen that their result are highly dependent, thus decreasing the efficiency of our structure.\n",
    "\n",
    "We should find a way to test the independence of our hash functions, but unfortunately it's actually **impossible** that they are exactly independent.\n",
    "\n",
    "In fact let's suppose for a moment that they are independent. Then taken any seven values $v = (v_{1},\\dots, v_{7})$ from $\\{0, 1, \\dots, 958505838\\}$ the probability $p_{(v_{1},\\dots, v_{7})}$ of getting $v$ after drawing a random string of $20$ characters subject to our restriction would be\n",
    "$$\n",
    "    p_{v_{1}}p_{v_{2}}\\cdots p_{v_{7}} = \\left(\\frac{1}{958505838}\\right)^{7} \\approx \\frac{1}{7 \\cdot 10^{62}}\n",
    "$$ at the same time it would be\n",
    "$$\n",
    "    p_{v} = \\sum_{s \\in S_{v}} p(s)\n",
    "$$ where $S_{v}$ is the set of strings giving $v$ after applying the seven hash functions. Given $s$ we have\n",
    "$$\n",
    "    p(s) = \\left(\\frac{1}{84}\\right)^{20} \\approx \\frac{1}{3 \\cdot 10^{38}}\n",
    "$$ but this means, by the second equation,\n",
    "$$\n",
    "    p_{(v_{1},\\dots, v_{7})} \\geq \\frac{1}{3 \\cdot 10^{38}}\n",
    "$$ which is totally in contrast with our first equation.\n",
    "\n",
    "Since we have proved that it's impossible to find seven hash functions exactly independent for our purpose, we're going to use the seven functions we have already coded, hoping they will be enough \"random\" for a good implementation of the bloom filter. The running time of our algorithm will help us finding out if everything works enough fine later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The algorithm\n",
    "We can finally code the algorithm for solving our task. We're going to code the solution in a function for a more organized and structured code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function takes as parameters the name of the file containing the first data set, the name of the file \n",
    "# containing the second data set, the size m of the array used to represen the bloom filter and\n",
    "# the list of hash functions used by the bloom filter\n",
    "\n",
    "# The function returns the number of strings from the second data set that are possibly contained in the first data set\n",
    "# and the execution time for finding this number\n",
    "def task(first_data_set, second_data_set, m, hash_functions):\n",
    "    \n",
    "    # We initialize our bloom filter\n",
    "    bloom_filter = Bloom_Filter(m, hash_functions)\n",
    "    \n",
    "    # We add every string in the first data set to the bloom filter\n",
    "    strings = open(first_data_set, \"r\")\n",
    "    start = time.time()\n",
    "    while(True):\n",
    "        string = strings.readline()\n",
    "        if(string == \"\"):\n",
    "            break\n",
    "        string = string[:len(string) - 1] # We need to get rid of the \"\\n\" at the end\n",
    "        bloom_filter.insert(string)\n",
    "    strings.close()\n",
    "    \n",
    "    # We now check how many strings from the second data set are probably on the first data set\n",
    "    # and we also create a list containing this possibly duplicates\n",
    "    strings = open(second_data_set, \"r\")\n",
    "    possibly_duplicates = []\n",
    "    while(True):\n",
    "        string = strings.readline()\n",
    "        if(string == \"\"):\n",
    "            break\n",
    "        string = string[:len(string) - 1]\n",
    "        if(bloom_filter.check(string)):\n",
    "            possibly_duplicates.append(string)\n",
    "    end = time.time()\n",
    "    strings.close()\n",
    "    \n",
    "    return((possibly_duplicates, end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to run the function and thus completing our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = task(\"passwords1.txt\", \"passwords2.txt\", 958505838, hash_functions)\n",
    "\n",
    "# We print the asked results\n",
    "print('Number of hash functions used: ', len(hash_functions))\n",
    "print('Number of possibly duplicates: ', len(result[0]))\n",
    "print('Probability of false positives: 0.01')\n",
    "print('Execution time: ', result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus\n",
    "Here we are going to count the exact number of false positives we got on the previous task. To do so we're going to use a hashing table and the hash function <code>hash_1</code> in the following way.\n",
    "\n",
    "We create an array <code>hash_duplicates</code> of size $958505838$ where every entry is a null value or a list of strings based on our list of possibly duplicates. In fact, for every string <code>s</code> in our list, we compute <code>hash_1(s)</code> and add that string to the <code>hash_1(s)</code>-th position of our first array.\n",
    "\n",
    "We then iterate over the first data set of passwords and for every password <code>p</code> we check if <code>p</code> is in the <code>hash_1(p)</code>-th position of our array. If the answer is yes we're going to remove that string from <code>hash_duplicates[hash_1(p)]</code>.\n",
    "\n",
    "In the end we iterate through <code>hash_duplicates</code> for reamining strings, those will be our false positives.\n",
    "\n",
    "Assuming that our hash function behaves well (and we hope so based on our discussions in the previous sections) all this process should take an amount of time linear in the size $n = 100000000$ of the first data set, which seems reasonable.\n",
    "\n",
    "So let's start by creating our array <code>hash_duplicates</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With this function we create an hash table of size size and with hash function hash_function and immediately\n",
    "# populate it with some data\n",
    "def hash_table(size, data, hash_function):\n",
    "    hash_array = np.empty(size, dtype = list)\n",
    "    for element in data:\n",
    "        index = hash_function(element)\n",
    "        if(hash_array[index] is None):\n",
    "            hash_array[index] = [element]\n",
    "        else:\n",
    "            hash_array[index].append(element)\n",
    "    return(hash_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Alphabetical Sort\n",
    "---\n",
    "### Counting sort\n",
    "In this section we're going to code the counting sort algorithm for sorting integers. Counting sort is pretty easy to implement for natural numbers, but we're going to extend it so it can also work with negative numbers, since that's not a too much difficult task.\n",
    "\n",
    "So, instead of searching the maximum of the array <code>to_sort</code> to be sorted, we're going to search both for the maximum as well for the minimum. This is just slightly more computational expensive, but the algorithm still runs in linear time.\n",
    "\n",
    "To do so, since of course python arrays can not have negative indexes, we are just going to shift the indexes based on our maximum and minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function takes an array of integers as parameter and it returns the sorted array\n",
    "def counting_sort(to_sort):\n",
    "    \n",
    "    # If the array is empty, there's nothing to sort\n",
    "    if(len(to_sort) == 0):\n",
    "        return(to_sort)\n",
    "    \n",
    "    # First of all we need to look for the maximum and minimum of the array\n",
    "    maximum = to_sort[0]\n",
    "    minimum = to_sort[0]\n",
    "    for index in range(1, len(to_sort)):\n",
    "        if(to_sort[index] > maximum):\n",
    "            maximum = to_sort[index]\n",
    "        if(to_sort[index] < minimum):\n",
    "            minimum = to_sort[index]\n",
    "    \n",
    "    # We now need to create an auxiliary array of size maximum - minimum + 1\n",
    "    aux_sorting = np.zeros(maximum - minimum + 1, dtype = int)\n",
    "    \n",
    "    # Here is the critical step of the algorithm, we're going to iterate through to_sort and for every element s\n",
    "    # we'll add one to aux_sorting[s - minimum]\n",
    "    for number in to_sort:\n",
    "        aux_sorting[number - minimum] += 1\n",
    "        \n",
    "    # Here we're finally going to create our sorted array and then return it\n",
    "    sorted_array = []\n",
    "    for index in range(len(aux_sorting)):\n",
    "        for _ in range(aux_sorting[index]):\n",
    "            sorted_array.append(index + minimum)\n",
    "    return(sorted_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try the function with some lists to make sure everything works as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_sort = [1, 2, 3, 4, 5]\n",
    "counting_sort(to_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_sort = [5, 4, 3, 2, 1]\n",
    "counting_sort(to_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-7, -3, -1, 0, 5, 9]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_sort = [-3, -7, 0, 9, 5, -1]\n",
    "counting_sort(to_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1054, -20, 0, 0, 0, 23, 201, 1001]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_sort = [1001, -20, 201, 0, -1054, 23, 0, 0]\n",
    "counting_sort(to_sort)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting the alphabet\n",
    "In this section we're going to use counting sort to sort a list containing all the letters of the alphabet.\n",
    "\n",
    "We start by an easy and crucial observation: even if we're sorting letters and not numbers, we can use the same algorithm just by working with the character codes of the letters instead of the letters themselves.\n",
    "\n",
    "So the algorithm is going to do the same steps as the previous one, the only difference is that we should first treat characters as numbers and then, when populating our sorted array at the end of the algorithm, we need to convert numbers back again to characters.\n",
    "\n",
    "This last task (the one of converting numbers back again to characters) is not problematic by itself, but we can work on the algorithm so that we won't need to do it and while this seems useless as of now, it has really good advantages in that we're going to code a lot more general and purpose-wise algorithm.\n",
    "\n",
    "What we do is we're just going to code our <code>counting_sort</code> function again, but this time it will take a second parameter: <code>key_function</code>, which will be a function to convert elements of the array <code>to_sort</code> into integers. For our particular task we're going to use the <code>ord</code> function.\n",
    "\n",
    "To make sure we don't need an inverse function to go back from numbers to the original members of the array, we're changing <code>aux_sorting</code> a bit. Instead of it being an array of numbers, it will be an array of tuples in a way that <code>aux_sorting[i]</code> has as first member the member of <code>to_sort</code> which is matched to <code>i</code> by <code>key_function</code> and as second member the counter just like before.\n",
    "\n",
    "At first it could seems that to correctly initialize <code>aux_sorting</code> this way, we need, for every <code>i</code> to know what element is matched to <code>i</code> by <code>key_function</code>, i.e. it seems we still need an inverse function. But that's not true because we don't need that **for every** <code>i</code> the first member of <code>aux_sorting[i]</code> is correct, but only for the ones we're actually using, i.e. the ones actually belonging to <code>to_sort</code>. This means we can populate <code>aux_sorting</code> during the counter whitout needing any inverse function.\n",
    "\n",
    "The last thing to note is that <code>key_function</code> should be a one-to-one function, at least when restricted to the elements of <code>to_sort</code>. We can not check this at runtime so we're just going to assume a good coder knows that, just like he should know to put an array of integers on our first counting sort and not an array of floats or boolean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes as parameter the array to be sorted and the key function\n",
    "# Note that the key function is set to the identity function to default, so that the algorithm will still run\n",
    "# when applied to an array of integers, whitout specifing the key function\n",
    "def counting_sort(to_sort, key_function = lambda x : x):\n",
    "    \n",
    "    # If the array is empty, there's nothing to sort\n",
    "    if(len(to_sort) == 0):\n",
    "        return(to_sort)\n",
    "    \n",
    "    # To start we creat an int_to_sort array which is just to_sort, but mapped with key_function\n",
    "    int_to_sort = list(map(key_function, to_sort))\n",
    "    \n",
    "    # Now we're going to work with int_to_sort and implementing basically the same counting sort\n",
    "    # algorithm as before\n",
    "    \n",
    "    # First of all we need to look for the maximum and minimum of the array\n",
    "    maximum = int_to_sort[0]\n",
    "    minimum = int_to_sort[0]\n",
    "    for index in range(1, len(int_to_sort)):\n",
    "        if(int_to_sort[index] > maximum):\n",
    "            maximum = int_to_sort[index]\n",
    "        if(int_to_sort[index] < minimum):\n",
    "            minimum = int_to_sort[index]\n",
    "    \n",
    "    # Now we create our auxiliary array, but as we have already said, it will be an array of tuples (of objects for np purposes)\n",
    "    aux_sorting = np.empty(maximum - minimum + 1, dtype = object)\n",
    "    \n",
    "    # Here is the critical step of the algorithm, we're going to iterate through to_sort and for every element s\n",
    "    # we'll add one to aux_sorting[key(s) - minimum][1], as well as s to aux_sorting[key(s) - minimum][0]\n",
    "    for index in range(len(int_to_sort)):\n",
    "        number = int_to_sort[index] - minimum\n",
    "        element = to_sort[index]\n",
    "        if(aux_sorting[number] is None):\n",
    "            aux_sorting[number] = [element, 1]\n",
    "        else:\n",
    "            aux_sorting[number][1] += 1\n",
    "    \n",
    "    # Here we're finally going to create our sorted array and then return it\n",
    "    sorted_array = []\n",
    "    for index in range(len(aux_sorting)):\n",
    "        if(not aux_sorting[index] is None):\n",
    "            for _ in range(aux_sorting[index][1]):\n",
    "                sorted_array.append(aux_sorting[index][0])\n",
    "    return(sorted_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now going to try our new function.\n",
    "\n",
    "First we'll try it with integers arrays whitout passing the <code>key_function</code> parameter to be sure it works as a generalization of our first implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 3, 4]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_sort = [2, 3, 4, 2]\n",
    "counting_sort(to_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-10, -3, 1, 1, 2, 9]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_sort = [2, -3, 9, 1, 1, -10]\n",
    "counting_sort(to_sort)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now try with a list containing the letters of the alphabet so to solve our initial task. As we have said at the start of the section we're going to pass the function <code>ord</code> to <code>key_function</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_sort = ['J', 'G', 'F', 'C', 'W', 'M', 'Z', 'Q', 'S', 'U', 'I', 'T', 'X', 'V', 'R', 'E', 'K', 'D', 'O', 'Y', 'L', 'N', 'A', 'P', 'H', 'B']\n",
    "counting_sort(to_sort, ord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can already start to see some advantages on the way we coded our function in that it works even if the alphabet is not complete or if there are letters appear more than once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B', 'D', 'H', 'H', 'I', 'O', 'R', 'Z']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_sort = ['H', 'I', 'Z', 'R', 'H', 'D', 'B', 'O']\n",
    "counting_sort(to_sort, ord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact our function works not only with letters of the alphabet, but with characters of any kind, as long as we want them to be sorted by their ASCII code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(', '-', '3', '4', '?', '?', 'A', 'b']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_sort = ['?', '(', 'b', '3', '-', '4', 'A', '?']\n",
    "counting_sort(to_sort, ord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a last example of how much our function can be versatile, we see that it can be used to sort a list of tuples by one of their coordinate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Paris', 'France', 2141),\n",
       " ('Rome', 'Italy', 2872),\n",
       " ('Los Angeles', 'USA', 3990),\n",
       " ('Beijing', 'China', 21542)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_sort = [('Rome', 'Italy', 2872), ('Paris', 'France', 2141), ('Los Angeles', 'USA', 3990), ('Beijing', 'China', 21542)]\n",
    "counting_sort(to_sort, lambda x : x[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting words\n",
    "It's time for the last algorithm of this task. Here we want to implement a variant of counting sort to sort list of words. Anyway there's not any variant to code, since we're going to use exactly our last function <code>counting_sort(to_sort, key_function)</code> with an appropriate choice of <code>key_function</code>.\n",
    "\n",
    "In fact if we find a function $f$ that given a word $s$ it returns an int $f(s)$ in such a way that if $s_{1}$ comes before $s_{2}$ in alphabetical order than $f(s_{1}) < f(s_{2})$ we can just use our couting sort function whitout having to change anything. So let's just look for this function $f$.\n",
    "\n",
    "It turns out that what we can do is to treat words like numbers in a different base, knowing the maximum lenght of a word is a fixed number $m$. Since the letters of the alphabet are $26$ we're going to treat words like numbers in base $27$, where the character \" \" (space) stands for zero (this will help us with multiword strings).\n",
    "\n",
    "Let's see how this work in more detail and why it works fine. Pick two words $s = s_{n}s_{n - 1}\\dots s_{1}$ and $t = t_{r}t_{r - 1}\\dots t_{1}$. First of all we're going to add at the end of the words as many spaces character as are needed to be sure both words have length exactly $m$. So, treating the space character as zero, we have $s = s_{n}s_{n - 1} \\dots s_{1}0\\dots0$ and $t = t_{r}t_{r - 1}\\dots t_{1}0 \\dots 0$. Treating these words as numbers in base $27$ and converting them to base $10$ we get:\n",
    "$$\n",
    "    s = s_{n} \\cdot 27^{m} + s_{n - 1} \\cdot 27^{m - 1} + \\cdots \\\\\n",
    "    t = t_{r} \\cdot 27^{m} + t_{r - 1} \\cdot 27^{m - 1} + \\cdots\n",
    "$$.\n",
    "\n",
    "Now it's clear that if $s_{n}$ comes before $t_{r}$ in alphabetical order, than $s < t$ since being both $s_{i}, t_{i} < 27$ for every $i$, what comes after $s_{n} \\cdot 27^{m}$ and $t_{r} \\cdot 27^{m}$ can't be bigger than these two terms, which will then dominate the ordering. If $s_{n} = t_{r}$ than we can pass to $s_{n - 1}$ and $t_{r - 1}$ and the same reasoning applies.\n",
    "\n",
    "If the first characters of both words are always equal before finding a character space we can also see that the smaller word in terms of lenght come before the other one, just like intended. In the same way we can see that this method work fine also for multiword strings.\n",
    "\n",
    "We have found our requested function $f$ theoretically speaking, now we just need to code it and that's what we will do right now. Just like we did on the first task for our hash function, to convert a word in base $10$ we're going to use Horner's method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function takes two parameters: the word to be converted to base 10 and the maximum lenght m which is needed\n",
    "# base on the previous discussion to order the list correctly\n",
    "def word_to_base_10(word, max_lenght):\n",
    "    \n",
    "    # first of all we're going to work with not capital letters\n",
    "    low_word = word.lower()\n",
    "    \n",
    "    # We then complete the word with spaces if needed\n",
    "    low_word = low_word + \" \" * (max_lenght - len(low_word))\n",
    "    \n",
    "    # We apply Horner's method to change base\n",
    "    value = 0\n",
    "    for index in range(len(low_word)):\n",
    "        single_char = 0\n",
    "        # We use ASCII code to get the base 10 value of a letter knowing that not capital letters\n",
    "        # start from 97\n",
    "        if(low_word[index] != ' '):\n",
    "            single_char = ord(low_word[index]) - 96\n",
    "        value = 27 * value + single_char\n",
    "    return(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to use our counting sort function for arrays of words all we just need to pass <code>word_to_base_10</code> to <code>key_function</code> parameter. This is actually not directly possible since in our counting sort implementation we assume <code>key_function</code> to take a single parameter, while <code>word_to_base_10</code> takes two of them. The problem can be easily solved with lambda functions, but for a more organized code we're going to code one more high order function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_base_10_function(max_lenght):\n",
    "    return(lambda x : word_to_base_10(x, max_lenght))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're finally ready to try out our algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['And', 'Bat', 'Bee', 'Dog', 'Eye', 'Go', 'Ten', 'To', 'Two']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_sort = [\"To\", \"Ten\", \"And\", \"Eye\", \"Bat\", \"Dog\", \"Two\", \"Go\", \"Bee\"]\n",
    "counting_sort(to_sort, word_to_base_10_function(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['As',\n",
       " 'Be',\n",
       " 'Cat',\n",
       " 'Hand',\n",
       " 'Like',\n",
       " 'Love',\n",
       " 'Nose',\n",
       " 'Rise',\n",
       " 'Than',\n",
       " 'Then',\n",
       " 'Zero']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_sort = [\"As\", \"Cat\", \"Like\", \"Be\", \"Zero\", \"Rise\", \"Then\", \"Nose\", \"Than\", \"Hand\", \"Love\"]\n",
    "counting_sort(to_sort, word_to_base_10_function(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Air',\n",
       " 'Lazy',\n",
       " 'Light',\n",
       " 'Mouse',\n",
       " 'Room',\n",
       " 'Shirt',\n",
       " 'Short',\n",
       " 'Sing',\n",
       " 'To be',\n",
       " 'To do',\n",
       " 'Tooth',\n",
       " 'While']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_sort = [\"Light\", \"Short\", \"Shirt\", \"To do\", \"Air\", \"Mouse\", \"Sing\", \"While\", \"Room\", \"Lazy\", \"Tooth\", \"To be\"]\n",
    "counting_sort(to_sort, word_to_base_10_function(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Both',\n",
       " 'Get up',\n",
       " 'Greedy',\n",
       " 'Ill',\n",
       " 'Laptop',\n",
       " 'List',\n",
       " 'Mirror',\n",
       " 'Poison',\n",
       " 'Random',\n",
       " 'Ready',\n",
       " 'Secure',\n",
       " 'Steady']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_sort = [\"Secure\", \"Get up\", \"Greedy\", \"Poison\", \"Both\", \"Random\", \"Laptop\", \"Ill\", \"List\", \"Mirror\", \"Ready\", \"Steady\"]\n",
    "counting_sort(to_sort, word_to_base_10_function(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything works great!\n",
    "### Time complexity\n",
    "Here we're going to discuss about time complexity of the counting sort algorithm we have coded. We'll start by doing that theoretically and then we'll do some empirical tries. We're going to use asymptotic notation and calculus, ignoring constants for the sake of simplicity.\n",
    "\n",
    "\n",
    "The first step of the algorithm is to convert the array <code>to_sort</code> into a new array using the function <code>key_function</code>. Let's say that $n$ is the size of <code>to_sort</code> and $\\Theta_{k}(m)$ is the time complexity of <code>key_function</code> where $m$ is a measure of the size of a single element of <code>to_sort</code> (since we're still analysing the algorithm in general terms we can't exactly say the value of $\\Theta_{k}(m)$ or what $m$ concretely represents). So the first step takes time (in the worst case that every element of the array to sort has exactly measure $m$):\n",
    "$$\n",
    "    \\Theta_{1}(n, m) = n\\Theta_{k}(m)\n",
    "$$.\n",
    "\n",
    "Next the algorithm look for the minimum as well for the maximum of the new array, and that clearly takes time:\n",
    "$$\n",
    "    \\Theta_{2}(n, m) = n\n",
    "$$.\n",
    "\n",
    "The third step is critical. We initialize a new array (the auxiliary one) and this takes time linear in its size. What the size of the new array is depends on our <code>key_function</code> so for now we're going to use a third variable $r$. This third step then takes time:\n",
    "$$\n",
    "    \\Theta_{3}(n, m, r) = r\n",
    "$$.\n",
    "\n",
    "We then iterate through all the first array and this takes time:\n",
    "$$\n",
    "    \\Theta_{4}(n, m, r) = n\n",
    "$$.\n",
    "\n",
    "In the end we iterate through all the auxiliary array and by doing so we're going to populate our new sorted array, which has lenght $n$, so for our last step we have:\n",
    "$$\n",
    "    \\Theta_{5}(n, m, r) = r + n\n",
    "$$.\n",
    "\n",
    "Putting everything together we have that counting sort has time complexity:\n",
    "$$\n",
    "    \\Theta(n, m, r) = n\\Theta_{k}(m) + n + r + n + r + n = n\\Theta_{k}(m) + \\Theta(n + r)\n",
    "$$.\n",
    "\n",
    "We see that even if the algorithm is linear in $n$, it can depends on other factors and measures that could potentially increase a lot its time complexity (and in fact we're going to see exactly this later on).\n",
    "\n",
    "Now let's see how this abstract formula applies to our specific cases, starting with counting sort applied to lists of integers. In this case <code>key_function</code> is just the identity function, so it's time complexity is of course constant $\\Theta_{k}(m) = 1$ ($m$ doesn't really makes sense as a variable here). Morevore we can see that $r$ is the difference between the maximum and minimum of the array, which we're going to call his range. So the time complexity of the counting sort algorithm is:\n",
    "$$\n",
    "    \\Theta(n, r) = n + \\Theta(n + r) = \\Theta(n + r)\n",
    "$$.\n",
    "\n",
    "We can thus deduce that the time complexity increases linearly both depending on the size of the array as well as on his range. If the size and the range are enough close this results in a efficient algorithm, but it could happen that the range is much bigger than the size and then other algorithms could be better.\n",
    "\n",
    "Let's move on to counting sort applied to lists containing all the letters of the alphabet (but in an unordere way). The <code>key_function</code> here is the <code>ord</code> function, which is again constant so, again, $\\Theta_{k}(m) = 1$ (and againg $m$ does not make sense here as a measure of anything). In this case, moreover, the range of the function is equal to his size (both are $26$), so $n = r$. In the end we have as time complexity:\n",
    "$$\n",
    "    \\Theta(n)\n",
    "$$. We could argue that in this case we know how big $n$ is so we could compute an explicit number for the time complexity, but that's not really needed. In the end the algorithm is pretty fast as the next empirical test shows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "to_sort = ['H', 'G', 'V', 'P', 'F', 'M', 'K', 'X', 'A', 'E', 'T', 'I', 'D', 'W', 'O', 'U', 'Z', 'Q', 'R', 'J', 'L', 'N', 'S', 'C', 'B', 'Y']\n",
    "start = time.time()\n",
    "counting_sort(to_sort, ord)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm runs in less than $0.05$ seconds, which is a totally reasonable amount of time.\n",
    "\n",
    "In the end let's see how our algorithm behaves when sorting a list of words. In this case we're going to put $m$ equal to the maximum lenght of the words to be sorted. Here <code>key_function</code> is <code>word_to_base_10</code>, which is easy to see having time complexity $\\Theta_{k}(m) = \\Theta(m)$. When looking at $r$ is where things get problematic. We can not say exactly how much $r$ is compared to $n$ and $m$, but let's see what happens in the worst scenario. This is when the array contains both the word of lenght $m$ with the maximum possible value in base $10$, as well as the word with the minimum possible value. The maximum one is $zz\\dots z$, which, converted to base $10$, is equal to $27^{m} - 1$. Yhe minimum one is $a$, which, converted to base $10$, is equal to $1$. So here the range is $r = 27^{m} - 1 -1 = 27^{m} - 2$. Finally the time complexity of the algorithm is then:\n",
    "$$\n",
    "    \\Theta(n, m) = n\\Theta_{k}(m) + \\Theta(n + 27^{m} - 2) = \\Theta(nm) + \\Theta(n + 27^{m}) = \\Theta(n + 27^{m})\n",
    "$$.\n",
    "\n",
    "The $\\Theta(27^{m})$ term is simply horrible. It increases way way faster than any reasonable function. Even when $m$ is low (like $m = 3$) it contributes to the running time with an unnecessary constant factor. When $m$ is greater than $3$ the algorithm already starts to be too much slow.\n",
    "\n",
    "In general the algorithm is bad in terms of time complexity. We could argue two things: first that the running time is bad in the worst case, but could be better in other situations and second that $n$ could be so big that it's the same order of $27^{m}$ and so it reamins a better choice than other algorithms like quick sort, which have a time complexity of $\\Theta(n\\ln n)$.\n",
    "\n",
    "Well, that's not the case, in both scenarios. In fact even if the array to be sorted does not contain the maximum and minimum possible word of lenght $m$, it's extremely unlikey that it does not contain at least two words starting with different letters. And if that's the case it's easy to see that the range $r$ is at least $27^{m - 1}$ which is still a really bad time complexity.\n",
    "\n",
    "Second it's highly unlikely that $n$ is greater than $27^{m}$. Just for example let's imagine we want to sort all the english words. There are english words with a lot of letters, but let's assume that no word goes beyond $7$ characters. This gives us a range of the order of $10^9$. The english words are estimated to be a number of the order of $10^{6}$. So we see that $n$ is highly smaller than $r$ and we repeat that we chose a maximum lenght $m$ smaller than what it really is.\n",
    "\n",
    "There's one last argument that could be considered. Maybe the algorithm is not bad by itself, but the choice of our <code>key_function</code> is and that's what brings a so big range $r$. But still, if we don't make any assumption on the words that could happen to be sorted, that's false. In fact whitouth any assumption it could happen that we find ourselves sorting all the possible words (even the ones without any meaning) of lenght $m$. For the algorithm to work properly we need that every word is mapped to a unique integer by our <code>key_function</code>. Since there are at least $26^{m}$ of these words (we're even not counting spaces and words with lenght smaller than $m$), we would need a range $r$ of at least $26^{m}$. So we see that our function is not really improvable to bring us to a smaller $r$.\n",
    "\n",
    "In the end let's test the time complexity of the algorithm empirically and see more concretely how bad it is. We're going to implement a function for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function takes as parameter an int max_lenght and returns a random word having that lenght\n",
    "# (a random word, not necessarily an english word)\n",
    "def random_word(max_lenght):\n",
    "    string = \"\"\n",
    "    for _ in range(max_lenght):\n",
    "        string = string + chr(rnd.randint(97, 122))\n",
    "    return(string)\n",
    "\n",
    "# The function takes as parameters the maximum lenght of words to be sorted and the number of them\n",
    "# it returns the runtime the algorithm counting sort takes to accomplish the goal\n",
    "def try_counting_sort(max_lenght_of_words, number_of_words):\n",
    "    \n",
    "    # Create a random list of words\n",
    "    to_sort = []\n",
    "    for _ in range(number_of_words):\n",
    "        to_sort.append(random_word(max_lenght_of_words))\n",
    "    \n",
    "    # Start counting runtime\n",
    "    start = time.time()\n",
    "    counting_sort(to_sort, word_to_base_10_function(max_lenght_of_words))\n",
    "    end = time.time()\n",
    "    \n",
    "    # Show the result\n",
    "    print(\"Runtime of the algorithm counting sort for sorting \" + str(number_of_words) + \" words of max lenght \" + str(max_lenght_of_words) + \" is \" + str(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to do our tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m = 3\n",
      "Runtime of the algorithm counting sort for sorting 10 words of max lenght 3 is 0.0010004043579101562\n",
      "Runtime of the algorithm counting sort for sorting 200 words of max lenght 3 is 0.0020008087158203125\n",
      "Runtime of the algorithm counting sort for sorting 1000 words of max lenght 3 is 0.005001068115234375\n",
      "\n",
      "m = 4\n",
      "Runtime of the algorithm counting sort for sorting 10 words of max lenght 4 is 0.042009592056274414\n",
      "Runtime of the algorithm counting sort for sorting 200 words of max lenght 4 is 0.04801011085510254\n",
      "Runtime of the algorithm counting sort for sorting 1000 words of max lenght 4 is 0.04901123046875\n",
      "\n",
      "m = 5\n",
      "Runtime of the algorithm counting sort for sorting 10 words of max lenght 5 is 1.2312774658203125\n",
      "Runtime of the algorithm counting sort for sorting 200 words of max lenght 5 is 1.1992616653442383\n",
      "Runtime of the algorithm counting sort for sorting 1000 words of max lenght 5 is 1.2608697414398193\n",
      "\n",
      "m = 6\n",
      "Runtime of the algorithm counting sort for sorting 10 words of max lenght 6 is 28.79049062728882\n",
      "Runtime of the algorithm counting sort for sorting 200 words of max lenght 6 is 32.29633045196533\n",
      "Runtime of the algorithm counting sort for sorting 1000 words of max lenght 6 is 32.20926308631897\n"
     ]
    }
   ],
   "source": [
    "for m in range(3, 7, 1):\n",
    "    if(m == 3):\n",
    "        print(\"m = 3\")\n",
    "    else:\n",
    "        print(\"\\nm = \" + str(m))\n",
    "    try_counting_sort(m, 10)\n",
    "    try_counting_sort(m, 200)\n",
    "    try_counting_sort(m, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Find similar wines!\n",
    "---\n",
    "### Implementation of k-means clustering\n",
    "In this section we're going to implement the naive k-means clustering algorithm. We're obviously going to do so with a function, but we'll need a bunch of other auxiliary ones before getting to it.\n",
    "\n",
    "We'll start from two simple geometric functions. One of them computes the squared euclidean distance between two points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function takes two parameters which are vectors in the form of arrays\n",
    "# It returns their squared euclidean distance\n",
    "def squared_distance(point_1, point_2):\n",
    "    squared_distance = 0\n",
    "    for index in range(len(point_1)):\n",
    "        squared_distance += (point_1[index] - point_2[index]) ** 2\n",
    "    return(squared_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we're coding a function which, given a set of points, it computes the mean of the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The functions takes one list of points as parameter and it returns its mean point\n",
    "def mean_of_set(set_of_points):\n",
    "    \n",
    "    # We set the mean equal to the first point just to have the same number of components\n",
    "    mean = set_of_points[0][:]\n",
    "    \n",
    "    # We compute the mean for every component individually\n",
    "    for coordinate in range(len(mean)):\n",
    "        component_sum = 0\n",
    "        for point in set_of_points:\n",
    "            component_sum += point[coordinate]\n",
    "        mean[coordinate] = component_sum / len(set_of_points)\n",
    "    return(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're coding a function which will be a critical step in ourt k-means clustering algorithm. It's for distributing a set of points into clusters estabilished by means. This is exactly the assignment step on the naive k-means clustering algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the function performing the assignment step of the clustering algorithm, it takes as parameters\n",
    "# all the points on the space and a list of means, it returns a list of clusters in such a way that every cluster is\n",
    "# associated to a mean and every point is on the cluster whose associated mean is closer to the point\n",
    "def assignment_step(all_points, means):\n",
    "    \n",
    "    # We'll start with a dict of means : points in the cluster associated to that mean\n",
    "    dict_clusters = dict()\n",
    "    for mean in means:\n",
    "        dict_cluster[mean] = []\n",
    "    \n",
    "    for point in all_points:\n",
    "        closest_distance = squared_distance(point, means[0])\n",
    "        closest_mean = means[0]\n",
    "        for mean in means:\n",
    "            new_distance = squared_distance(point, mean)\n",
    "            if(new_distance < closest_distance):\n",
    "                closest_distance = new_distance\n",
    "                closest_mean = mean\n",
    "        dict_clusters[closest_mean].append(point)\n",
    "    \n",
    "    # We only need the clusters, not the starting means\n",
    "    return(dict_clusters.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
